device = cpu
simulation_speed = 1
state_size = 44
action_size = 5
hidden_size = 512
input_size = 44
batch_size = 128
buffer_size = 1000000
discount_factor = 0.99
learning_rate = 0.003
tau = 0.003
step_time = 0.01
loss_function = <function smooth_l1_loss at 0x7fdf4eb7cc10>
epsilon = 1.0
epsilon_decay = 0.9995
epsilon_minimum = 0.05
reward_function = A
backward_enabled = False
stacking_enabled = False
stack_depth = 3
frame_skip = 4
networks = [Actor(
  (fa1): Linear(in_features=44, out_features=512, bias=True)
  (fa2): Linear(in_features=512, out_features=512, bias=True)
  (fa3): Linear(in_features=512, out_features=5, bias=True)
), Actor(
  (fa1): Linear(in_features=44, out_features=512, bias=True)
  (fa2): Linear(in_features=512, out_features=512, bias=True)
  (fa3): Linear(in_features=512, out_features=5, bias=True)
)]
iteration = 0
possible_actions = [[0.3, -1.0], [0.3, -0.5], [1.0, 0.0], [0.3, 0.5], [0.3, 1.0]]
target_update_frequency = 1000
actor_optimizer = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.003
    maximize: False
    weight_decay: 0.01
)

